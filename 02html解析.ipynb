{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "re\n",
    "bs4\n",
    "xpath 推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ls = re.findall(r\"\\d+\", \"123345\")\n",
    "print(ls)\n",
    "# iter效率高\n",
    "it = re.finditer(r\"\\d+\", \"123我45\")\n",
    "for i in it:\n",
    "    print(i.group())\n",
    "# re.search匹配一个结果\n",
    "# re.match从头开始匹配\n",
    "\n",
    "#预加载正则表达式\n",
    "obj = re.compile(r\"\\d+\")\n",
    "it = obj.finditer(\"124 1254\")\n",
    "print(it)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "s = \"\"\"\n",
    "<div class='jay'><span id='1'>周杰伦</span></div>\n",
    "<div class='kk'><span id='2'>zzq</span></div>\n",
    "\"\"\"\n",
    "\n",
    "# re.S 让.能匹配换行符\n",
    "# obj = re.compile(r\"<div class='.*?'><span id='\\d+'>.*?</span></div>\", re.S)\n",
    "# result = obj.finditer(s)\n",
    "# for i in result:\n",
    "#     print(i.group())\n",
    "\n",
    "# (?P<分组名字>正则表达式)从正则里面提取\n",
    "obj = re.compile(r\"<div class='.*?'><span id='\\d+'>(?P<name>.*?)</span></div>\", re.S)\n",
    "result = obj.finditer(s)\n",
    "for i in result:\n",
    "    print(i.group('name'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import csv\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'\n",
    "}\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "page_content = resp.text\n",
    "resp.close()\n",
    "\n",
    "obj = re.compile(r'<li>.*?<div class=\"item\">.*?<span class=\"title\">(?P<title>.*?)</span>'\n",
    "                 r'.*?<p class=\"\">.*?<br>(?P<year>.*?)&nbsp.*?'\n",
    "                 r'<span class=\"rating_num\" property=\"v:average\">(?P<score>.*?)</span>'\n",
    "                 r'.*?<span>(?P<num>.*?)人评价</span>', re.S)\n",
    "\n",
    "results = obj.finditer(page_content)\n",
    "\n",
    "f = open('data.csv', 'w')\n",
    "cw = csv.writer(f)\n",
    "\n",
    "for it in results:\n",
    "    dic = it.groupdict()\n",
    "    dic['year'] = dic['year'].strip()\n",
    "    cw.writerow(dic.values())\n",
    "    print(it.group(\"title\"), end=' ')\n",
    "    print(it.group(\"year\").strip(), end=' ')\n",
    "    print(it.group(\"score\"), end=' ')\n",
    "    print(it.group(\"num\"))\n",
    "\n",
    "f.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# install bs4\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.xinfadi.com.cn/marketanalysis/0/list/1.shtml'\n",
    "resp = requests.get(url)\n",
    "# print(resp.text)\n",
    "\n",
    "# 解析数据\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "# 查找数据 find一个 findall全部，获取总表\n",
    "table = page.find(\"table\", class_=\"hq_table\")\n",
    "# print(table) 获取每一行\n",
    "trs = table.find_all(\"tr\")[1:]\n",
    "\n",
    "for tr in trs:\n",
    "    tds = tr.find_all(\"td\")\n",
    "    print(tds)\n",
    "    for td in tds:\n",
    "        print(td.text)\n",
    "\n",
    "resp.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% bs4\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "url = 'https://www.umei.net/bizhitupian/weimeibizhi/'\n",
    "\n",
    "resp = requests.get(url)\n",
    "resp.encoding = 'utd-8'\n",
    "\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "TypeList = page.find(\"div\", class_='TypeList').find_all(\"a\")\n",
    "\n",
    "for a in TypeList:\n",
    "    href = 'https://www.umei.net/' + a.get('href')\n",
    "    child_page_resp = requests.get(href)\n",
    "    child_page_resp.encoding = 'utd-8'\n",
    "    child_page = BeautifulSoup(child_page_resp.text, 'html.parser')\n",
    "    img = child_page.find(\"p\", align=\"center\").find('img')\n",
    "    print(img.get('src'))\n",
    "    src = img.get('src')\n",
    "    #下载图片\n",
    "    img_resp = requests.get(src)\n",
    "    img_name = src.split(\"/\")[-1]\n",
    "\n",
    "    with open('img/'+img_name, mode='wb') as f:\n",
    "        f.write(img_resp.content)\n",
    "    child_page_resp.close()\n",
    "    time.sleep(1)\n",
    "\n",
    "resp.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "xpath 是在xml文档中搜索内容的一门语言\n",
    "html 是xml的一个子集\n",
    "pip install lxml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.jianshu.com/p/85a3004b5c06\n",
    "\n",
    "表达式\t描述\n",
    "nodename\t选取此节点的所有子节点\n",
    "/\t从当前节点选区直接子节点\n",
    "//\t从当前节点选取子孙节点\n",
    ".\t选取当前节点\n",
    "..\t选取当前节点的父节点\n",
    "@\t选取属性\n",
    "这里列出了 XPath 的常用匹配规则，示例如下：\n",
    "\n",
    "//title[@lang='eng']\n",
    "这是一个 XPath 规则，代表的是选择所有名称为 title，同时属性 lang 的值为 eng 的节点，后面会通过 Python 的 lxml 库，利用 XPath 进行 HTML 的解析。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "xml = \"\"\"\n",
    "<book>\n",
    "    <name>123</name>\n",
    "    <author>456</author>\n",
    "</book>\n",
    "\"\"\"\n",
    "\n",
    "#etree.HTML\n",
    "tree = etree.XML(xml)\n",
    "\n",
    "result = tree.xpath('/book')\n",
    "print(result)\n",
    "\n",
    "result = tree.xpath('/book/name')\n",
    "print(result)\n",
    "\n",
    "result = tree.xpath('/book/name/text()')\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "url = \"https://ganzhou.zbj.com/search/f/?type=new&kw=saas\"\n",
    "\n",
    "resp = requests.get(url)\n",
    "\n",
    "html = etree.HTML(resp.text)\n",
    "\n",
    "divs = html.xpath(\"/html/body/div[6]/div/div/div[2]/div[5]/div[1]/div\")\n",
    "\n",
    "for div in divs:\n",
    "    try:\n",
    "        price = div.xpath(\"./div/div/a[1]/div[2]/div[1]/span[1]/text()\")[0].strip(\"¥\")\n",
    "        title = 'saas'.join(div.xpath(\"./div/div/a[1]/div[2]/div[2]/p/text()\"))\n",
    "        print(price, title)\n",
    "    except:\n",
    "        continue\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 猪八戒网\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}